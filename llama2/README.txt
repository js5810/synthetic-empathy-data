To do inference with Llama 2 using the scripts here please follow these steps:

1. Go to https://github.com/meta-llama/llama/tree/main and follow their quick start directions (you only need to download llama-2-7b-chat in your cloned repository)

2. Execute "pip install -r requirements.txt" to download all the dependencies

3. Add both chat_completion.py and infer.sh into your cloned repo

4. Execute "bash ./infer.sh" in your terminal which will run the inference command
